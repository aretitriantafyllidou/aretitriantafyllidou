{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02345d2",
   "metadata": {},
   "source": [
    "# Text processing and sentiment Analysis\n",
    "\n",
    "## Research Question 1\n",
    "Do ESG-focused communications influence consumer sentiment and trust?\n",
    "\n",
    "Hypotheses:\n",
    "- H1: ESG ads positively impact consumer trust \n",
    "- H1a: Inauthentic ESG ads create negative sentiment (backlash)\n",
    "\n",
    "Methodology:\n",
    "1. Text preprocessing (cleaning, translation)\n",
    "2. RoBERTa sentiment classification\n",
    "3. BART zero-shot refinement for low-confidence neutrals\n",
    "4. Purchase intent detection\n",
    "5. Statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3c46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from langdetect import detect, DetectorFactory\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Settings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Load data \n",
    "df = pd.read_csv(\"campaign_comments.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e324a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## text cleaning\n",
    "\n",
    "URL_RE = re.compile(r\"http\\S+\")\n",
    "USER_RE = re.compile(r\"@\\w+\")\n",
    "\n",
    "def clean_text(txt: str) -> str:\n",
    "    if pd.isna(txt):\n",
    "        return \"\"\n",
    "    txt = str(txt)\n",
    "    txt = URL_RE.sub(\" <URL> \", txt)\n",
    "    txt = USER_RE.sub(\" <USER> \", txt)\n",
    "    txt = txt.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
    "    return re.sub(r\"\\s{2,}\", \" \", txt).strip()\n",
    "\n",
    "df[\"clean\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "print(\"\\nðŸ”§ Cleaning Example:\")\n",
    "print(f\"Original: {df['text'].iloc[0]}\")\n",
    "print(f\"Cleaned:  {df['clean'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97568702",
   "metadata": {},
   "outputs": [],
   "source": [
    "##language detection \n",
    "\n",
    "def safe_detect(txt):\n",
    "    try:\n",
    "        return detect(txt) if txt.strip() else \"unknown\"\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "df[\"lang\"] = df[\"clean\"].apply(safe_detect)\n",
    "\n",
    "lang_dist = df[\"lang\"].value_counts()\n",
    "print(lang_dist.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36abaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation to english\n",
    "\n",
    "from transformers import pipeline as hf_pipe\n",
    "\n",
    "translator = hf_pipe(\n",
    "    task=\"translation\",\n",
    "    model=\"facebook/nllb-200-distilled-600M\",\n",
    "    src_lang=\"auto\",\n",
    "    tgt_lang=\"eng_Latn\",\n",
    "    max_length=256,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "print(\"Translator loaded\")\n",
    "\n",
    "def to_english(row):\n",
    "    if row.lang in [\"en\", \"unknown\"]:\n",
    "        return row.clean\n",
    "    try:\n",
    "        tr = translator(row.clean, max_length=256)[0][\"translation_text\"]\n",
    "        return str(tr).lower()\n",
    "    except:\n",
    "        return row.clean\n",
    "\n",
    "df[\"clean_en\"] = df.apply(to_english, axis=1)\n",
    "print(\" complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f784792b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment classification\n",
    "\n",
    "#roberta sentiment \n",
    "\n",
    "sent_clf = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    tokenizer=\"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "sent_out = sent_clf(df[\"clean_en\"].tolist(), batch_size=32)\n",
    "df[\"roberta_sentiment\"] = [o[\"label\"].lower() for o in sent_out]\n",
    "df[\"sent_score\"] = [o[\"score\"] for o in sent_out]\n",
    "print(df[\"roberta_sentiment\"].value_counts())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38248a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "###  Zero-Shot Refinement (BART)\n",
    "#Reclassify low-confidence neutral comments (<0.85) using BART.\n",
    "\n",
    "zs_clf = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\",\n",
    "    truncation=True\n",
    ")\n",
    "ZS_SENTIMENT_LABELS = [\"positive\", \"neutral\", \"negative\"]\n",
    "\n",
    "def classify_sentiment_zs(text):\n",
    "    \"\"\"Zero-shot sentiment classification.\"\"\"\n",
    "    try:\n",
    "        out = zs_clf(\n",
    "            text,\n",
    "            candidate_labels=ZS_SENTIMENT_LABELS,\n",
    "            hypothesis_template=\"This comment expresses a {} sentiment.\"\n",
    "        )\n",
    "        return out[\"labels\"][0].lower()\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "# Apply only to low-confidence neutrals\n",
    "neutral_mask = (df[\"roberta_sentiment\"] == \"neutral\") & (df[\"sent_score\"] < 0.85)\n",
    "df[\"zero_shot_sentiment\"] = None\n",
    "df.loc[neutral_mask, \"zero_shot_sentiment\"] = df.loc[neutral_mask, \"clean_en\"].apply(classify_sentiment_zs)\n",
    "\n",
    "\n",
    "# Emotional Positive Detection\n",
    "#Rule-based detection for highly emotional positive language.\n",
    "\n",
    "\n",
    "\n",
    "EMOTIONAL_POSITIVE_PHRASES = [\n",
    "    \"made me cry\", \"i cried\", \"crying\", \"tears\", \"emotional\",\n",
    "    \"so touching\", \"beautiful\", \"inspiring\", \"goosebumps\",\n",
    "    \"love this\", \"uplifting\", \"empowering\", \"gave me chills\",\n",
    "    \"stunning\", \"heartwarming\", \"ðŸ˜­\", \"ðŸ¥²\", \"ðŸ¥¹\"\n",
    "]\n",
    "\n",
    "def is_emotional_positive(text):\n",
    "    text_lower = str(text).lower()\n",
    "    return any(p in text_lower for p in EMOTIONAL_POSITIVE_PHRASES)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae2dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Final Sentiment Decision\n",
    "#Combine RoBERTa, zero-shot, and emotional detection.\n",
    "\n",
    "\n",
    "def choose_final_sentiment(row):\n",
    "    \"\"\"\n",
    "    Decision hierarchy:\n",
    "    1. Emotional positive phrases then positive\n",
    "    2. RoBERTa if not neutral then use RoBERTa sentiment\n",
    "    3. RoBERTa neutral with high confidence (â‰¥0.85) then neutral\n",
    "    4. Zero-shot result we use  use zero-shot\n",
    "    5. Default then neutral\n",
    "    \"\"\"\n",
    "    if is_emotional_positive(row.get(\"clean_en\", \"\")):\n",
    "        return \"positive\"\n",
    "    if row[\"roberta_sentiment\"] != \"neutral\":\n",
    "        return row[\"roberta_sentiment\"]\n",
    "    if row[\"sent_score\"] >= 0.85:\n",
    "        return \"neutral\"\n",
    "    zs = row.get(\"zero_shot_sentiment\", \"unknown\")\n",
    "    if zs in [\"positive\", \"negative\"]:\n",
    "        return zs\n",
    "    return \"neutral\"\n",
    "\n",
    "df[\"final_sentiment\"] = df.apply(choose_final_sentiment, axis=1)\n",
    "\n",
    "print(\"\\n Final Sentiment Distribution:\")\n",
    "print(df[\"final_sentiment\"].value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Purchase Intent Analysis\n",
    "\n",
    "## Detect purchase intentions using keywords + zero-shot classification.\n",
    "\n",
    "POS_KW = {\"buy\", \"buying\", \"bought\", \"purchase\", \"order\", \"need this\"}\n",
    "NEG_KW = {\"won't buy\", \"not buying\", \"too expensive\", \"overpriced\", \"never buy\"}\n",
    "\n",
    "def has_kw(text, kw_set):\n",
    "    \"\"\"Check if text contains keywords, word boundaries for single words).\"\"\"\n",
    "    t = str(text).lower()\n",
    "    for kw in kw_set:\n",
    "        if \" \" in kw:\n",
    "            if kw in t:\n",
    "                return True\n",
    "        else:\n",
    "            if re.search(rf\"\\b{re.escape(kw)}\\b\", t):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def classify_purchase_keywords(text):\n",
    "    \"\"\"Keyword-based purchase intent classification.\"\"\"\n",
    "    if has_kw(text, POS_KW):\n",
    "        return \"Purchase_Pos\"\n",
    "    if has_kw(text, NEG_KW):\n",
    "        return \"Purchase_Neg\"\n",
    "    return \"NoPurchase\"\n",
    "\n",
    "df[\"purchase_intent_keywords\"] = df[\"clean_en\"].apply(classify_purchase_keywords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933f293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot purchase intent\n",
    "ZS_PURCHASE_LABELS = [\"Purchase_Pos\", \"Purchase_Neg\", \"NoPurchase\"]\n",
    "\n",
    "def classify_purchase_zs(text):\n",
    "    try:\n",
    "        out = zs_clf(\n",
    "            text,\n",
    "            candidate_labels=ZS_PURCHASE_LABELS,\n",
    "            hypothesis_template=\"This comment expresses {} behavior.\"\n",
    "        )\n",
    "        return out[\"labels\"][0]\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "df[\"purchase_intent_zs\"] = df[\"clean_en\"].apply(classify_purchase_zs)\n",
    "\n",
    "print(df[\"purchase_intent_zs\"].value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b264da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Weighted Net Sentiment\n",
    "\n",
    "#Calculate weighted sentiment using likes as engagement weight.\n",
    "\n",
    "df[\"weight\"] = np.sqrt(df[\"likes\"].fillna(0) + 1)\n",
    "sent_val_map = {\"positive\": 1, \"neutral\": 0, \"negative\": -1}\n",
    "df[\"sent_val\"] = df[\"final_sentiment\"].map(sent_val_map)\n",
    "weighted_net = (df[\"sent_val\"] * df[\"weight\"]).sum() / df[\"weight\"].sum()\n",
    "\n",
    "print(f\"\\n Weighted Net Sentiment: {weighted_net:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af878fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics per campaign for regression analysis\n",
    "\n",
    "# Calculate percentages\n",
    "sent_counts = df[\"final_sentiment\"].value_counts()\n",
    "sent_percent = (sent_counts / len(df)) * 100\n",
    "\n",
    "print(\"\\n Final Sentiment Summary:\")\n",
    "print(f\"Positive: {sent_percent.get('positive', 0):.1f}%\")\n",
    "print(f\"Neutral:  {sent_percent.get('neutral', 0):.1f}%\")\n",
    "print(f\"Negative: {sent_percent.get('negative', 0):.1f}%\")\n",
    "\n",
    "purchase_pos_pct = (df[\"purchase_intent_zs\"] == \"Purchase_Pos\").mean() * 100\n",
    "print(f\"Purchase Intent (Positive): {purchase_pos_pct:.1f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8dc960",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizations\n",
    "\n",
    "\n",
    "# Sentiment distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sent_counts.plot(kind='bar', color=['green', 'gray', 'red'])\n",
    "plt.title('Sentiment Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Purchase intent\n",
    "plt.figure(figsize=(10, 6))\n",
    "df[\"purchase_intent_zs\"].value_counts().plot(kind='bar', color=['green', 'red', 'gray'])\n",
    "plt.title('Purchase Intent Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Intent')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('purchase_intent.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
