{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dee374c",
   "metadata": {},
   "source": [
    "# ESG Advertising Analysis: Data Collection\n",
    "\n",
    " Overview\n",
    "\n",
    "This project analyzes 90 marketing campaigns (65 ESG, 25 non-ESG) from 63 publicly \n",
    "traded companies (2010-2024) to measure:\n",
    " Consumer sentiment via social media (YouTube, Twitter)\n",
    " Financial market reactions via event study analysis\n",
    "Each advertising has its own dataset\n",
    "We create each data set from youtube in csv and we process it.\n",
    "\n",
    "Data Sources:\n",
    "- YouTube API: 49 campaigns \n",
    "- Twitter API: 22 campaigns \n",
    "- Yahoo Finance: Stock price data\n",
    "\n",
    "\n",
    "## YouTube Data Collection\n",
    "Using Google API to scrape comments from ESG advertising campaigns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee04f8ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'googleapiclient'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogleapiclient\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdiscovery\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'googleapiclient'"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# YouTube API Key and Video ID\n",
    "API_KEY = 'private' \n",
    "VIDEO_ID = 'Put the ID of youtube video you want to install'\n",
    "\n",
    "# we create YouTube API client\n",
    "youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
    "\n",
    "# from this we take all top-level comments\n",
    "def get_top_level_comments(video_id):\n",
    "    top_comments = []\n",
    "    comment_ids = []\n",
    "\n",
    "    request = youtube.commentThreads().list(\n",
    "        part='snippet',\n",
    "        videoId=video_id,\n",
    "        maxResults=100,\n",
    "        textFormat='plainText'\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    while request:\n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']\n",
    "            comment_id = item['id']\n",
    "\n",
    "            top_comments.append({\n",
    "                'comment_id': comment_id,\n",
    "                'text': comment.get('textDisplay'),\n",
    "                'author': comment.get('authorDisplayName'),\n",
    "                'likes': comment.get('likeCount', 0),\n",
    "                'published_at': comment.get('publishedAt'),\n",
    "                'is_reply': False,\n",
    "                'parent_id': None,\n",
    "                'parent_author': None\n",
    "            })\n",
    "            comment_ids.append((comment_id, comment.get('authorDisplayName')))\n",
    "\n",
    "        if 'nextPageToken' in response:\n",
    "            request = youtube.commentThreads().list(\n",
    "                part='snippet',\n",
    "                videoId=video_id,\n",
    "                pageToken=response['nextPageToken'],\n",
    "                maxResults=100,\n",
    "                textFormat='plainText'\n",
    "            )\n",
    "            response = request.execute()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return top_comments, comment_ids\n",
    "\n",
    "    # thisis if we want the replies as well\n",
    "def get_replies_for_comment(comment_id, parent_author):\n",
    "    replies = []\n",
    "    request = youtube.comments().list(\n",
    "        part='snippet',\n",
    "        parentId=comment_id,\n",
    "        maxResults=100,\n",
    "        textFormat='plainText'\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    while request:\n",
    "        for item in response['items']:\n",
    "            snippet = item['snippet']\n",
    "            replies.append({\n",
    "                'comment_id': item['id'],\n",
    "                'text': snippet.get('textDisplay'),\n",
    "                'author': snippet.get('authorDisplayName'),\n",
    "                'likes': snippet.get('likeCount', 0),\n",
    "                'published_at': snippet.get('publishedAt'),\n",
    "                'is_reply': True,\n",
    "                'parent_id': comment_id,\n",
    "                'parent_author': parent_author\n",
    "            })\n",
    "\n",
    "        if 'nextPageToken' in response:\n",
    "            request = youtube.comments().list(\n",
    "                part='snippet',\n",
    "                parentId=comment_id,\n",
    "                pageToken=response['nextPageToken'],\n",
    "                maxResults=100,\n",
    "                textFormat='plainText'\n",
    "            )\n",
    "            response = request.execute()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return replies\n",
    "\n",
    "# run and we scrap top-level + replies\n",
    "all_comments = []\n",
    "top_level, top_ids = get_top_level_comments(VIDEO_ID)\n",
    "all_comments.extend(top_level)\n",
    "\n",
    "print(f\" Top-level comments: {len(top_level)}\")\n",
    "\n",
    "# \n",
    "reply_total = 0\n",
    "for comment_id, author in top_ids:\n",
    "    replies = get_replies_for_comment(comment_id, author)\n",
    "    all_comments.extend(replies)\n",
    "    reply_total += len(replies)\n",
    "    time.sleep(0.1)  \n",
    "\n",
    "print(f\" Replies were collected : {reply_total}\")\n",
    "print(f\" Total comments : {len(all_comments)}\")\n",
    "\n",
    "# we save in csv\n",
    "df = pd.DataFrame(all_comments)\n",
    "\n",
    "# save\n",
    "output_path = '/Users/ourname/Desktop/name.csv'  # Mac\n",
    "# output_path = r'C:\\Users\\ourname\\Desktop\\name.csv'  # Windows\n",
    "\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a2a0a5",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Dataset Overview\n",
    "\n",
    "**Structure:**\n",
    "- `comment_id`: Unique identifier\n",
    "- `text`: Comment content\n",
    "- `author`: Username\n",
    "- `likes`: Engagement metric\n",
    "- `published_at`: Timestamp\n",
    "- `is_reply`: Boolean flag\n",
    "- `parent_id`: For threading\n",
    "- `parent_author`: Original commenter\n",
    "\n",
    "\n",
    "- I repeated for all 90 campaigns\n",
    "- Then I Merged with campaign metadata (Company, ESG theme, Date)\n",
    "- and next is sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1581a3a1",
   "metadata": {},
   "source": [
    "##  Twitter Data Collection\n",
    "\n",
    "Fot twitter comments, Ampify was used to exctrat tweets from users and comments from advertising.\n",
    "\n",
    "https://apify.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
